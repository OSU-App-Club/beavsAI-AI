# Â© 2023 App Development Club @ Oregon State Unviersity
# All Rights Reserved

# This file exposes a REST API that can be used to interact with the Pinecone vector store.
# It is intended to be used as a reference for how to use Pinecone in a production environment.
# It is not intended to be used as a production server.
# For example, it does not have any authentication or rate limiting.

# All of the functionality in this file can be used for free with the starter indexes/environment.

# However, if you're wanting to extend this and add expanded functionality, you
# will need to upgrade to a paid plan and put that in your .env file.

import json
import logging
import os
import re
import uuid
from datetime import datetime, timedelta
from typing import Optional, Union

import pinecone
import uvicorn
from constants import course_map, data_map
from dotenv import load_dotenv
from fastapi import Depends, FastAPI, File, HTTPException, UploadFile, status
from jose import JWTError, jwt
from langchain.chains.question_answering import load_qa_chain
from langchain.document_loaders import UnstructuredPDFLoader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.llms import OpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Pinecone
from starlette.middleware.cors import CORSMiddleware
from pydantic import BaseModel

origins = [
    "http://localhost:8080",
    "http://localhost:8000",
    "http://localhost:5173",
    "http://127.0.0.1:5173",
]

# Create the FastAPI app
app = FastAPI()

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://0.0.0.0:8080", "https://beavsai.onrender.com", "https://beavsai-backend.onrender.com"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class LoadDocuemnts(BaseModel):
    class_name: str


class IndexInfo(BaseModel):
    vectorCount: int
    dimension: int
    indexFullness: float
    totalVectorCount: int


class PineconeInfo(BaseModel):
    namespaces: list
    dimension: int
    indexFullness: float
    totalVectorCount: int


class GetResponse(BaseModel):
    class_name: str
    query: str


# Generate mapping for data
def generate_mapping(filenames):
    mapping = []
    for filename in filenames:
        crn_matcher = re.search(r"CS(\d+)_", filename)
        crn = crn_matcher.group(1) if crn_matcher else None
        term = (
            "F23"
            if filename.endswith("F23.pdf")
            else "S22"
            if filename.endswith("S22.pdf")
            else "unknown"
        )
        index = f"cs{crn.lower()}-index" if crn else None
        course_name = course_map[crn] if crn else None
        mapping.append(
            {
                "index": index,
                "filename": filename,
                "term": term,
                "crn": crn,
                "course_name": course_name,
            }
        )
    return mapping


# Add pdf to pinecone index
async def add_pdf_to_pinecone_index(pdf_path, index_name, embeddings):
    print("tmertn", index_name)
    if index_name is None:
        return {"error": "Index name is required"}

    existing_indexes = pinecone.list_indexes()

    if existing_indexes:
        if existing_indexes[0] != index_name:
            if existing_indexes[0] is not None:
                print("deleting index")
                print(existing_indexes[0])
                pinecone.delete_index(existing_indexes[0])
            pinecone.create_index(name=index_name, metric="cosine", dimension=1536)
        else:
            print("index already exists")
            res = await upload_pdf(pdf_path, index_name, embeddings)
            print(res)
            return {"error": res["error"]}
    else:
        pinecone.create_index(name=index_name, metric="cosine", dimension=1536)

    if index_name in pinecone.list_indexes():
        await upload_pdf(pdf_path, index_name, embeddings)

    return {"error": "PDF uploaded successfully"}


async def upload_pdf(pdf_path, index_name, embeddings):
    existing_indexes = pinecone.list_indexes()
    if existing_indexes:
        index_info = pinecone.Index(index_name).describe_index_stats()
        print(index_info)
        if index_info.namespaces == {}:
            vector_count = index_info.total_vector_count
            if vector_count == 0:
                loader = UnstructuredPDFLoader(pdf_path)
                data = loader.load()
                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=1000, chunk_overlap=0, separators=[" ", ",", "\n"]
                )
                texts = text_splitter.split_documents(data)
                docsearch = Pinecone.from_documents(
                    texts, embeddings, index_name=index_name
                )
                return {"error": "PDF uploaded successfully"}
            else:
                return {"error": "Index already has a document"}
        else:
            return {"error": "Index already has documents"}
    else:
        return {"error": "Index does not exist"}


# Load .env
load_dotenv()
OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]
PINECONE_API_KEY = os.environ["PINECONE_API_KEY"]
PINECONE_API_ENV = os.environ["PINECONE_API_ENV"]
SECRET_KEY = os.environ["SECRET_KEY"]
ALGORITHM = os.environ["ALGORITHM"]
ACCESS_TOKEN_EXPIRE_MINUTES = os.environ["ACCESS_TOKEN_EXPIRE_MINUTES"]

pinecone.init(
    api_key=PINECONE_API_KEY,
    environment=PINECONE_API_ENV,
)

embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)


# hello world
@app.get("/")
def read_root():
    return {"Hello": "World"}


# Upload syllabus
@app.post("/upload")
async def create_upload_file(file: UploadFile = File(...)):
    with open(f"../data/syllabus/{file.filename}", "wb") as local_file:
        local_file.write(file.file.read())
    return {
        "filename": file.filename,
        "content_type": file.content_type,
        "location": f"../data/syllabus/{file.filename}",
    }


# Load documents into Pinecone
@app.post("/load_documents")
async def load_documents(load_documents: LoadDocuemnts):
    crn = None
    for item in data_map:
        if item["course_name"] == load_documents.class_name:
            crn = item["crn"]
            break
    syllabus_directory = "../data/syllabus"
    index_name = f"cs{crn.lower()}-index"
    pdf_path = None
    for item in data_map:
        if item["index"] == index_name:
            pdf_path = f"{syllabus_directory}/{item['filename']}"
            break
    status = await add_pdf_to_pinecone_index(pdf_path, index_name, embeddings)
    return {"status": status}


# Get q&a for a class classname w/ query
@app.post("/response")
async def get_response(get_response: GetResponse):
    index_name = f"cs{get_response.class_name.lower()}-index"
    docsearch = Pinecone.from_existing_index(index_name, embeddings)
    docs = docsearch.similarity_search(get_response.query)
    llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)
    chain = load_qa_chain(llm, chain_type="stuff")
    llm_response = chain.run(input_documents=docs, question=get_response.query)
    return {"response": llm_response}


# List all indexes
@app.get("/list_indexes")
async def list_indexes():
    return pinecone.list_indexes()


# Get information about an index
@app.get("/list_index_info/{index_name}")
async def list_index_info(index_name: str):
    return pinecone.describe_index(index_name)


# Get all available data
@app.get("/available_data")
def available_data():
    return data_map


# Uvicorn isn't required, but it's a nice way to run a webserver in python
if __name__ == "__main__":
    if os.environ.get("RENDER") == True or os.environ.get("RENDER") == "true" or os.environ.get("RENDER") == "True":
        uvicorn.run("main:app", host="0.0.0.0", port=10000, reload=False)
    else:
        uvicorn.run("main:app", host="localhost", port=8080, reload=True)
